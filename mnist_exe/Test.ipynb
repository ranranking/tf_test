{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from model import *\n",
    "from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/ranranking/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/ranranking/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/ranranking/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/ranranking/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/ranranking/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc\n",
    "LOG_DIR = './log/'\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1\n",
    "num_steps = 500\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "num_classes = 10\n",
    "keep_rate = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trn_x = mnist.train.images.reshape([-1, 28, 28, 1])\n",
    "mnist_trn_y = mnist.train.labels\n",
    "\n",
    "mnist_val_x = mnist.validation.images.reshape([-1, 28, 28, 1])\n",
    "mnist_val_y = mnist.validation.labels\n",
    "\n",
    "mnist_test_x = mnist.test.images.reshape([-1, 28, 28, 1])\n",
    "mnist_test_y = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_graph = tf.Graph()\n",
    "with model_graph.as_default():\n",
    "    \n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Dataset Preparation\n",
    "    mnist_trn_ds = tf.data.Dataset.from_tensor_slices((mnist_trn_x, mnist_trn_y)).shuffle(500).batch(batch_size)\n",
    "    mnist_val_ds = tf.data.Dataset.from_tensor_slices((mnist_val_x, mnist_val_y)).shuffle(500).batch(batch_size)\n",
    "    mnist_test_ds = tf.data.Dataset.from_tensor_slices((mnist_test_x, mnist_test_y)).batch(batch_size)\n",
    "    \n",
    "    # String Handle\n",
    "    handle = tf.placeholder(tf.string, [])\n",
    "    iterator = tf.data.Iterator.from_string_handle(handle, mnist_trn_ds.output_types, mnist_trn_ds.output_shapes)\n",
    "    next_element = iterator.get_next()\n",
    "    \n",
    "    # Dataset iterators\n",
    "    training_iterator = mnist_trn_ds.make_initializable_iterator()\n",
    "    validation_iterator = mnist_val_ds.make_initializable_iterator()\n",
    "    testing_iterator = mnist_test_ds.make_one_shot_iterator()\n",
    "    \n",
    "    # Image Summary\n",
    "    tf.summary.image('input', next_element[0], 3)\n",
    "    \n",
    "    # Logits and Predictions\n",
    "    logits, embedding_input = build_model(next_element[0], next_element[1], keep_prob) \n",
    "    prediction = {'classes': tf.argmax(logits, axis=1), \n",
    "                  'prob': tf.nn.softmax(logits, name='prob')}\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    with tf.variable_scope('cross_entropy_loss'):\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=next_element[1]))\n",
    "        tf.summary.scalar('cross_entropy_loss', loss)\n",
    "    \n",
    "    with tf.variable_scope('train'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evaluation\n",
    "    with tf.variable_scope('accuracy'):\n",
    "        correct_pred = tf.equal(prediction['classes'], tf.argmax(next_element[1], 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "    # Global Initializer\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    \n",
    "    # Summary\n",
    "    summary = tf.summary.merge_all()\n",
    "    \n",
    "    # Embedding\n",
    "    embedding = tf.Variable(tf.zeros([1024, 1024]), name='test_embedding')\n",
    "    assignment = embedding.assign(embedding_input)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "    embedding_config = config.embeddings.add()\n",
    "    embedding_config.tensor_name = embedding.name\n",
    "    embedding_config.metadata_path = 'labels.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 0, Minibatch Loss= 3.1904, Training Accuracy= 0.062\n",
      "Epoch 0, Step 10, Minibatch Loss= 2.1221, Training Accuracy= 0.375\n",
      "Epoch 0, Step 20, Minibatch Loss= 1.2844, Training Accuracy= 0.633\n",
      "Epoch 0, Step 30, Minibatch Loss= 0.7739, Training Accuracy= 0.695\n",
      "Epoch 0, Step 40, Minibatch Loss= 0.4812, Training Accuracy= 0.844\n",
      "Epoch 0, Step 50, Minibatch Loss= 0.4937, Training Accuracy= 0.875\n",
      "Epoch 0, Step 60, Minibatch Loss= 0.4183, Training Accuracy= 0.883\n",
      "Epoch 0, Step 70, Minibatch Loss= 0.3643, Training Accuracy= 0.898\n",
      "Epoch 0, Step 80, Minibatch Loss= 0.1484, Training Accuracy= 0.953\n",
      "Epoch 0, Step 90, Minibatch Loss= 0.0933, Training Accuracy= 0.977\n",
      "Validation, Minibatch Loss= 0.1877, Training Accuracy= 0.946\n",
      "Epoch 0, Step 100, Minibatch Loss= 0.2182, Training Accuracy= 0.945\n",
      "Epoch 0, Step 110, Minibatch Loss= 0.2267, Training Accuracy= 0.922\n",
      "Epoch 0, Step 120, Minibatch Loss= 0.1527, Training Accuracy= 0.945\n",
      "Epoch 0, Step 130, Minibatch Loss= 0.1991, Training Accuracy= 0.953\n",
      "Epoch 0, Step 140, Minibatch Loss= 0.1413, Training Accuracy= 0.945\n",
      "Epoch 0, Step 150, Minibatch Loss= 0.1431, Training Accuracy= 0.969\n",
      "Epoch 0, Step 160, Minibatch Loss= 0.1144, Training Accuracy= 0.961\n",
      "Epoch 0, Step 170, Minibatch Loss= 0.0821, Training Accuracy= 0.969\n",
      "Epoch 0, Step 180, Minibatch Loss= 0.1788, Training Accuracy= 0.930\n",
      "Epoch 0, Step 190, Minibatch Loss= 0.1030, Training Accuracy= 0.930\n",
      "Validation, Minibatch Loss= 0.0990, Training Accuracy= 0.971\n",
      "Epoch 0, Step 200, Minibatch Loss= 0.0340, Training Accuracy= 0.992\n",
      "Epoch 0, Step 210, Minibatch Loss= 0.1363, Training Accuracy= 0.945\n",
      "Epoch 0, Step 220, Minibatch Loss= 0.1052, Training Accuracy= 0.977\n",
      "Epoch 0, Step 230, Minibatch Loss= 0.1593, Training Accuracy= 0.945\n",
      "Epoch 0, Step 240, Minibatch Loss= 0.1462, Training Accuracy= 0.922\n",
      "Epoch 0, Step 250, Minibatch Loss= 0.0604, Training Accuracy= 0.984\n",
      "Epoch 0, Step 260, Minibatch Loss= 0.1025, Training Accuracy= 0.961\n",
      "Epoch 0, Step 270, Minibatch Loss= 0.0588, Training Accuracy= 0.992\n",
      "Epoch 0, Step 280, Minibatch Loss= 0.0598, Training Accuracy= 0.984\n",
      "Epoch 0, Step 290, Minibatch Loss= 0.1117, Training Accuracy= 0.969\n",
      "Validation, Minibatch Loss= 0.0814, Training Accuracy= 0.976\n",
      "Epoch 0, Step 300, Minibatch Loss= 0.1042, Training Accuracy= 0.969\n",
      "Epoch 0, Step 310, Minibatch Loss= 0.1622, Training Accuracy= 0.938\n",
      "Epoch 0, Step 320, Minibatch Loss= 0.2059, Training Accuracy= 0.945\n",
      "Epoch 0, Step 330, Minibatch Loss= 0.0447, Training Accuracy= 0.984\n",
      "Epoch 0, Step 340, Minibatch Loss= 0.0528, Training Accuracy= 0.984\n",
      "Epoch 0, Step 350, Minibatch Loss= 0.0555, Training Accuracy= 0.977\n",
      "Epoch 0, Step 360, Minibatch Loss= 0.0808, Training Accuracy= 0.984\n",
      "Epoch 0, Step 370, Minibatch Loss= 0.0571, Training Accuracy= 0.984\n",
      "Epoch 0, Step 380, Minibatch Loss= 0.0424, Training Accuracy= 0.984\n",
      "Testing, Minibatch Loss= 0.0768, Training Accuracy= 0.974\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=model_graph) as sess:\n",
    "    \n",
    "    # Debugger\n",
    "    #sess = tf_debug.TensorBoardDebugWrapperSession(sess, \"MZQ-MBP.local:7000\")\n",
    "    \n",
    "    # Writer\n",
    "    writer = tf.summary.FileWriter('./log/model_1', graph=model_graph)\n",
    "    \n",
    "    # Embedding projector\n",
    "    #tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)\n",
    "    \n",
    "    # Run Global Initializer\n",
    "    sess.run(initializer)\n",
    "    \n",
    "    # Iterator Handles\n",
    "    training_handle = sess.run(training_iterator.string_handle())\n",
    "    validation_handle = sess.run(validation_iterator.string_handle())\n",
    "    testing_handle = sess.run(testing_iterator.string_handle())\n",
    "    \n",
    "    step = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        sess.run(training_iterator.initializer)\n",
    "        while True:\n",
    "            # Training\n",
    "            try:\n",
    "                sess.run(train_op, feed_dict={keep_prob: keep_rate, handle: training_handle})\n",
    "\n",
    "                if step % display_step == 0:\n",
    "\n",
    "                    loss_val, acc, s = sess.run([loss, accuracy, summary],\n",
    "                                                feed_dict={keep_prob: 1.0, handle: training_handle})\n",
    "\n",
    "                    writer.add_summary(s, step)\n",
    "\n",
    "                    print(\"Epoch \" + str(epoch) + \", Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss_val) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "                    \n",
    "                step += 1\n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "\n",
    "            # Validation\n",
    "            if step % (display_step * 10) == 0 and step != 0:\n",
    "\n",
    "#                 sess.run(assignment, feed_dict={images: mnist.test.images[:1024].reshape([-1, 28, 28, 1]),\n",
    "#                                                 labels: mnist.test.labels[:1024]})            \n",
    "#                 saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), step)\n",
    "\n",
    "                sess.run(validation_iterator.initializer)\n",
    "\n",
    "                val_acc = 0\n",
    "                val_loss = 0\n",
    "                validation_iter = 0\n",
    "\n",
    "                while True:\n",
    "                    try:\n",
    "                        loss_val, acc = sess.run([loss, accuracy], feed_dict={keep_prob: 1.0, handle: validation_handle})\n",
    "                        val_acc += acc\n",
    "                        val_loss += loss_val\n",
    "                        validation_iter += 1\n",
    "                    except tf.errors.OutOfRangeError:\n",
    "                        break\n",
    "\n",
    "                assert validation_iter != 0\n",
    "                print(\"Validation\" + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(val_loss/validation_iter) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(val_acc/validation_iter))\n",
    "\n",
    "\n",
    "    # Testing\n",
    "    test_acc = 0\n",
    "    test_loss = 0\n",
    "    testing_iter = 0\n",
    "\n",
    "    while True:        \n",
    "        try:\n",
    "            loss_val, acc = sess.run([loss, accuracy], feed_dict={keep_prob: 1.0, handle: testing_handle})\n",
    "            test_acc += acc\n",
    "            test_loss += loss_val\n",
    "            testing_iter += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "    assert testing_iter != 0\n",
    "    print(\"Testing\" + \", Minibatch Loss= \" + \\\n",
    "          \"{:.4f}\".format(test_loss/testing_iter) + \", Training Accuracy= \" + \\\n",
    "          \"{:.3f}\".format(test_acc/testing_iter))\n",
    "            \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Steps\n",
    "Don't forget to use:\n",
    "\n",
    "```\n",
    "mnist_trn_ds = tf.data.Dataset.from_tensor_slices((mnist_trn_x, mnist_trn_y)).shuffle(500).batch(batch_size)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Minibatch Loss= 2.5452, Training Accuracy= 0.164\n",
      "Step 10, Minibatch Loss= 1.5652, Training Accuracy= 0.469\n",
      "Step 20, Minibatch Loss= 0.6957, Training Accuracy= 0.836\n",
      "Step 30, Minibatch Loss= 0.4986, Training Accuracy= 0.836\n",
      "Step 40, Minibatch Loss= 0.2813, Training Accuracy= 0.914\n",
      "Step 50, Minibatch Loss= 0.3131, Training Accuracy= 0.914\n",
      "Step 60, Minibatch Loss= 0.1990, Training Accuracy= 0.961\n",
      "Step 70, Minibatch Loss= 0.1807, Training Accuracy= 0.961\n",
      "Step 80, Minibatch Loss= 0.2785, Training Accuracy= 0.922\n",
      "Step 90, Minibatch Loss= 0.1874, Training Accuracy= 0.953\n",
      "Step 100, Minibatch Loss= 0.1178, Training Accuracy= 0.969\n",
      "Validation, Minibatch Loss= 0.1400, Training Accuracy= 0.962\n",
      "Step 110, Minibatch Loss= 0.1117, Training Accuracy= 0.977\n",
      "Step 120, Minibatch Loss= 0.1339, Training Accuracy= 0.961\n",
      "Step 130, Minibatch Loss= 0.0982, Training Accuracy= 0.969\n",
      "Step 140, Minibatch Loss= 0.1018, Training Accuracy= 0.961\n",
      "Step 150, Minibatch Loss= 0.1889, Training Accuracy= 0.938\n",
      "Step 160, Minibatch Loss= 0.1277, Training Accuracy= 0.953\n",
      "Step 170, Minibatch Loss= 0.1414, Training Accuracy= 0.961\n",
      "Step 180, Minibatch Loss= 0.2064, Training Accuracy= 0.938\n",
      "Step 190, Minibatch Loss= 0.2076, Training Accuracy= 0.945\n",
      "Step 200, Minibatch Loss= 0.1356, Training Accuracy= 0.969\n",
      "Validation, Minibatch Loss= 0.0922, Training Accuracy= 0.973\n",
      "Step 210, Minibatch Loss= 0.0470, Training Accuracy= 0.992\n",
      "Step 220, Minibatch Loss= 0.0465, Training Accuracy= 0.984\n",
      "Step 230, Minibatch Loss= 0.1125, Training Accuracy= 0.953\n",
      "Step 240, Minibatch Loss= 0.0547, Training Accuracy= 0.992\n",
      "Step 250, Minibatch Loss= 0.0519, Training Accuracy= 0.984\n",
      "Step 260, Minibatch Loss= 0.1214, Training Accuracy= 0.953\n",
      "Step 270, Minibatch Loss= 0.0733, Training Accuracy= 0.984\n",
      "Step 280, Minibatch Loss= 0.0210, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 0.1079, Training Accuracy= 0.977\n",
      "Step 300, Minibatch Loss= 0.1805, Training Accuracy= 0.969\n",
      "Validation, Minibatch Loss= 0.0956, Training Accuracy= 0.971\n",
      "Step 310, Minibatch Loss= 0.0932, Training Accuracy= 0.977\n",
      "Step 320, Minibatch Loss= 0.1190, Training Accuracy= 0.977\n",
      "Step 330, Minibatch Loss= 0.0427, Training Accuracy= 0.984\n",
      "Step 340, Minibatch Loss= 0.1385, Training Accuracy= 0.977\n",
      "Step 350, Minibatch Loss= 0.0224, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.0483, Training Accuracy= 0.984\n",
      "Step 370, Minibatch Loss= 0.0914, Training Accuracy= 0.969\n",
      "Step 380, Minibatch Loss= 0.0118, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.0864, Training Accuracy= 0.961\n",
      "Step 400, Minibatch Loss= 0.0656, Training Accuracy= 0.969\n",
      "Validation, Minibatch Loss= 0.0869, Training Accuracy= 0.974\n",
      "Step 410, Minibatch Loss= 0.0825, Training Accuracy= 0.977\n",
      "Step 420, Minibatch Loss= 0.0754, Training Accuracy= 0.977\n",
      "Step 430, Minibatch Loss= 0.0556, Training Accuracy= 0.984\n",
      "Step 440, Minibatch Loss= 0.1362, Training Accuracy= 0.984\n",
      "Step 450, Minibatch Loss= 0.0516, Training Accuracy= 0.992\n",
      "Step 460, Minibatch Loss= 0.0740, Training Accuracy= 0.977\n",
      "Step 470, Minibatch Loss= 0.1037, Training Accuracy= 0.969\n",
      "Step 480, Minibatch Loss= 0.0713, Training Accuracy= 0.984\n",
      "Step 490, Minibatch Loss= 0.0738, Training Accuracy= 0.977\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-826b9b6d2e1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtest_iter\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", Minibatch Loss= \"\u001b[0m \u001b[0;34m+\u001b[0m           \u001b[0;34m\"{:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtesting_iter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", Training Accuracy= \"\u001b[0m \u001b[0;34m+\u001b[0m           \u001b[0;34m\"{:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtesting_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=model_graph) as sess:\n",
    "    \n",
    "    # Debugger\n",
    "    #sess = tf_debug.TensorBoardDebugWrapperSession(sess, \"MZQ-MBP.local:7000\")\n",
    "    \n",
    "    # Writer\n",
    "    writer = tf.summary.FileWriter('./log/model_1', graph=model_graph)\n",
    "    \n",
    "    # Embedding projector\n",
    "    #tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)\n",
    "    \n",
    "    # Run Global Initializer\n",
    "    sess.run(initializer)\n",
    "    \n",
    "    # Iterator Handles\n",
    "    training_handle = sess.run(training_iterator.string_handle())\n",
    "    validation_handle = sess.run(validation_iterator.string_handle())\n",
    "    testing_handle = sess.run(testing_iterator.string_handle())\n",
    "    \n",
    "    # Training\n",
    "    for step in range(num_steps):\n",
    "        # Training\n",
    "        try:\n",
    "            sess.run(train_op, feed_dict={keep_prob: keep_rate, handle: training_handle})\n",
    "\n",
    "            if step % display_step == 0:\n",
    "\n",
    "                loss_val, acc, s = sess.run([loss, accuracy, summary],\n",
    "                                            feed_dict={keep_prob: 1.0, handle: training_handle})\n",
    "\n",
    "                writer.add_summary(s, step)\n",
    "\n",
    "                print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(loss_val) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(acc))\n",
    "                \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "            \n",
    "        # Validation\n",
    "        if step % (display_step * 10) == 0 and step != 0:\n",
    "            \n",
    "            sess.run(validation_iterator.initializer)\n",
    "            \n",
    "            val_acc = 0\n",
    "            val_loss = 0\n",
    "            validation_iter = 0\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    loss_val, acc = sess.run([loss, accuracy], feed_dict={keep_prob: 1.0, handle: validation_handle})\n",
    "                    val_acc += acc\n",
    "                    val_loss += loss_val\n",
    "                    validation_iter += 1\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "                \n",
    "            assert validation_iter != 0\n",
    "            print(\"Validation\" + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(val_loss/validation_iter) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(val_acc/validation_iter))\n",
    "            \n",
    "#         if step % 100 == 0:\n",
    "            \n",
    "#             sess.run(assignment, feed_dict={images: mnist.test.images[:1024].reshape([-1, 28, 28, 1]),\n",
    "#                                             labels: mnist.test.labels[:1024]})\n",
    "#             saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), step)\n",
    "\n",
    "\n",
    "    # Testing\n",
    "    test_acc = 0\n",
    "    test_loss = 0\n",
    "    testing_iter = 0\n",
    "\n",
    "    while True:        \n",
    "        try:\n",
    "            loss_val, acc = sess.run([loss, accuracy], feed_dict={keep_prob: 1.0, handle: testing_handle})\n",
    "            test_acc += acc\n",
    "            test_loss += loss_val\n",
    "            testing_iter += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "    assert testing_iter != 0\n",
    "    print(\"Testing\" + \", Minibatch Loss= \" + \\\n",
    "          \"{:.4f}\".format(test_loss/testing_iter) + \", Training Accuracy= \" + \\\n",
    "          \"{:.3f}\".format(test_acc/testing_iter))\n",
    "            \n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
